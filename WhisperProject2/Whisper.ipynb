{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Whisper\n",
      "  Using cached whisper-1.1.10-py3-none-any.whl\n",
      "Requirement already satisfied: six in ./WhispAI/lib/python3.12/site-packages (from Whisper) (1.17.0)\n",
      "Installing collected packages: Whisper\n",
      "Successfully installed Whisper-1.1.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/Documents/Whisper/WhispAI/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/Documents/Whisper/WhispAI/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Good job. Glad to see things are going well and business is starting to pick up. Andrea told me about your outstanding numbers on Tuesday. Keep up the good work. Now to other business, I am going to suggest a payment schedule for the outstanding money that is due. One, can you pay the balance of the license agreement as soon as possible? Two, I suggest we set up or you suggest what you can pay on the back rawties. What do you feel comfortable with paying every two weeks? Every month. I would like to keep, I would like to catch up and maintain current royalties. So if we can start current royalties and maintain them every two weeks as all stores are required to do, I would appreciate it. Let me know if this works for you. Thanks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model.transcribe(\"audio.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Text:  Good job. Glad to see things are going well and business is starting to pick up. Andrea told me about your outstanding numbers on Tuesday. Keep up the good work. Now to other business, I am going to suggest a payment schedule for the outstanding money that is due. One, can you pay the balance of the license agreement as soon as possible? Two, I suggest we set up or you suggest what you can pay on the back rawties. What do you feel comfortable with paying every two weeks? Every month. I would like to keep, I would like to catch up and maintain current royalties. So if we can start current royalties and maintain them every two weeks as all stores are required to do, I would appreciate it. Let me know if this works for you. Thanks.\n"
     ]
    }
   ],
   "source": [
    "# Print the transcribed text\n",
    "print(\"Transcribed Text:\", result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Language: en\n",
      "Segments:\n",
      "Start: 0.0s, End: 11.36s, Text:  Good job. Glad to see things are going well and business is starting to pick up.\n",
      "Start: 11.36s, End: 21.96s, Text:  Andrea told me about your outstanding numbers on Tuesday. Keep up the good work.\n",
      "Start: 21.96s, End: 33.96s, Text:  Now to other business, I am going to suggest a payment schedule for the outstanding\n",
      "Start: 33.96s, End: 49.36s, Text:  money that is due. One, can you pay the balance of the license agreement as soon as possible?\n",
      "Start: 49.36s, End: 62.96s, Text:  Two, I suggest we set up or you suggest what you can pay on the back rawties. What do\n",
      "Start: 62.96s, End: 87.08s, Text:  you feel comfortable with paying every two weeks? Every month. I would like to keep, I\n",
      "Start: 87.08s, End: 104.12s, Text:  would like to catch up and maintain current royalties. So if we can start current royalties\n",
      "Start: 104.12s, End: 115.16s, Text:  and maintain them every two weeks as all stores are required to do, I would appreciate it.\n",
      "Start: 115.16s, End: 122.16s, Text:  Let me know if this works for you. Thanks.\n"
     ]
    }
   ],
   "source": [
    "# Print the detected language\n",
    "print(\"Detected Language:\", result['language'])\n",
    "\n",
    "# Print segment details if available\n",
    "print(\"Segments:\")\n",
    "for segment in result['segments']:\n",
    "    print(f\"Start: {segment['start']}s, End: {segment['end']}s, Text: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved as transcription.srt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to convert Whisper segments to SRT format\n",
    "def save_as_srt(segments, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for idx, segment in enumerate(segments):\n",
    "            # Format start and end times to SRT format (HH:MM:SS,MS)\n",
    "            start_time = segment['start']\n",
    "            end_time = segment['end']\n",
    "            start_time_srt = format_time_to_srt(start_time)\n",
    "            end_time_srt = format_time_to_srt(end_time)\n",
    "            \n",
    "            # Write index, timestamps, and text to the file\n",
    "            f.write(f\"{idx + 1}\\n\")\n",
    "            f.write(f\"{start_time_srt} --> {end_time_srt}\\n\")\n",
    "            f.write(f\"{segment['text']}\\n\\n\")\n",
    "\n",
    "# Function to format time to SRT format (HH:MM:SS,MS)\n",
    "def format_time_to_srt(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{secs:02},{ms:03}\"\n",
    "\n",
    "# Save the transcription as an SRT file\n",
    "srt_filename = \"transcription.srt\"\n",
    "save_as_srt(result['segments'], srt_filename)\n",
    "\n",
    "print(f\"Transcription saved as {srt_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WhispAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
